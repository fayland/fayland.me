---
category: sphinx
layout: post
tags:
  - haproxy
  - sphinx
title: all about sphinx
---
{% include JB/setup %}

for those who don't know sphinx yet, sphinx is <a href="http://sphinxsearch.com/">http://sphinxsearch.com/</a> full text search engine.<br /><b><br />1. geo distance</b><br /><br />It has been quite popular for location application recently. see you have a user table with lat/lon data, and you want to find out the nearest people or order by distance.<br /><br />it's pretty hard to do it with SQL but very easy with sphinx. sample:<br /><br />* the config file:<br /><blockquote>sql_query = SELECT user_id, radians(longitude) as longitude, radians(latitude) as latitude FROM user_location<br />sql_attr_float = longitude<br />sql_attr_float = latitude<br /></blockquote>* perl sample code:<br /><blockquote>my $pi = atan2(1,1) * 4;<br />sub deg2rad {<br />&nbsp;&nbsp;&nbsp; my ($deg) = @_;<br />&nbsp;&nbsp;&nbsp; return ($deg * $pi / 180);<br />}<br /></blockquote><blockquote>$sphinx-&gt;SetMatchMode(SPH_MATCH_EXTENDED);<br />$sphinx-&gt;SetSortMode(SPH_SORT_EXTENDED, '@geodist ASC');<br />#### $lat/$lon is the point you want to be based on<br />$sphinx-&gt;SetGeoAnchor('latitude', 'longitude', deg2rad($lat), deg2rad($lon));<br />#### $radius is how far you want to search with<br />my $circle = $radius * 1.609344; # meter<br />$sphinx-&gt;SetFilterFloatRange('@geodist', 0, $circle);<br />my $ret = $sphinx-&gt;Query();<br /></blockquote>it's simple, sphinx did all the magic you want. the stuff you want to know is that sphinx can do it. :)<br /><br /><b>2. haproxy as load balancer</b><br /><br />when you have many sphinx servers, one choice is that you can do disturbed index as mentioned <a href="http://sphinxsearch.com/docs/current.html#distributed">in the doc</a>. the other is to put load balancer before them.<br />well, I'm not saying the built-in disturbed index is bad or something like that, actually I haven't tried that yet. below is just my cents when I use haproxy with sphinx servers.<br /><br />* when you put 'log 127.0.0.1&nbsp;&nbsp; local0' in the conf, don't forget to follow the docs with google search, put 'local0.* /var/log/haproxy.log' and the "-r" in SYSLOGD_OPTIONS="-m 0 -r"<br /><br />actually I'm not 100% satisfied with haproxy.<br />* haproxy doesn't support TCP stats like http as I tested with haproxy 1.4.13<br />* haproxy can't check sphinx searchd status. it's not the fault of haproxy, searchd doesn't have a simple way to verify it's working smoothly or have fatal error inside. it can be fixed by a Perl script but I'd like that searchd has this inside.<br /><br />but it really works pretty well, I may write a Perl script as the 'check' in haproxy so that it can auto failover then I think I'll be more happy.<br /><br /><b>3. new rotating way</b><br /><br />To do full index on every sphinx server is really dumb. it puts heavy load on the underlying MySQL server. Big thanks to the sphinx forum, I have the answer to do something like below and it works pretty good.<br /><br />steps:<br />* create a new index section in the conf<br /><blockquote>index XXX {<br />&nbsp;&nbsp;&nbsp; source = XXX<br />&nbsp;&nbsp;&nbsp; path &nbsp;&nbsp; = /var/data/sphinx/XXX<br />&nbsp;&nbsp;&nbsp; .........<br />}<br />index XXX_new : XXX {<br />&nbsp;&nbsp;&nbsp; path = /var/data/sphinx/new/XXX.new<br />}<br /></blockquote>* never run indexer --all on XXX, instead, always run it with<br />indexer --all --config /path/to/above.conf XXX_new<br />* run bash or Perl script to do the full index, after run the command above. copy those XXX.new.sp* to destination by cp or scp. then send kill -1 to the pid of searchd which can use `cat /the/pid/file/in/conf/XXX.pid`. (-1 is SIGHUP).<br />* NOTE here: when you do the -&gt;Query API call, you have to put XXX as the second arg as index name. or it will search with XXX;XXX_new, and it wastes. (or you can try start the searchd with --index XXX)<br /><br />the real magic here is that<br />if you run indexer --all with XXX. it will create XXX.new.sp* file. and once you sent the SIGHUP by --rotate or restart the searchd, the XXX.new.sp* will becomes XXX.sp*<br />so you can run the indexer --all with XXX_new, and it will generate XXX.new.sp* which is the same as the ones you do it with --all XXX, and you can copy it to the directory XXX.sp* lives, and SIGHUP can make it becomes XXX.sp* without any fault.<br /><br />well, not funny but maybe useful when you have the same situation.<br /><br />Thanks.<br />